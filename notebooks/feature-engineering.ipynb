{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ada187",
   "metadata": {},
   "source": [
    "# Feature Engineering and Data Preparation\n",
    "\n",
    "This notebook transforms cleaned transaction datasets into feature-rich,\n",
    "model-ready formats. It includes time-based features, transaction behavior\n",
    "features, scaling, encoding, and proper handling of class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d538600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the neccessary dependecies...\n",
      "succussfully imported\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing the neccessary dependecies...\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(\"succussfully imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34395861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from processed and raw file\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading from processed and raw file\")\n",
    "fraud_df = pd.read_csv(\"./data/processed/fraud_cleaned.csv\")\n",
    "credit_df = pd.read_csv(\"./data/processed/creditcard_cleaned.csv\")\n",
    "ip_df = pd.read_csv(\"./data/raw/IpAddress_to_Country.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107b1623",
   "metadata": {},
   "source": [
    "### Country Feature\n",
    "\n",
    "We enrich the dataset by mapping IP addresses to countries.\n",
    "This geographic signal can improve fraud detection accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8205cdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lower_bound_ip_address  upper_bound_ip_address    country\n",
      "0                16777216                16777471  Australia\n",
      "1                16777472                16777727      China\n",
      "2                16777728                16778239      China\n",
      "3                16778240                16779263  Australia\n",
      "4                16779264                16781311      China\n"
     ]
    }
   ],
   "source": [
    "print(ip_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "038c125a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP addresses converted to integers\n"
     ]
    }
   ],
   "source": [
    "# Convert IP addresses to integer\n",
    "fraud_df[\"ip_int\"] = fraud_df[\"ip_address\"].astype(int)\n",
    "\n",
    "ip_df[\"lower_bound_ip_address\"] = ip_df[\"lower_bound_ip_address\"].astype(int)\n",
    "ip_df[\"upper_bound_ip_address\"] = ip_df[\"upper_bound_ip_address\"].astype(int)\n",
    "\n",
    "print(\"IP addresses converted to integers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00f9aec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "United States     58049\n",
      "Unknown           21966\n",
      "China             12038\n",
      "Japan              7306\n",
      "United Kingdom     4490\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def find_country(ip):\n",
    "    match = ip_df[\n",
    "        (ip_df[\"lower_bound_ip_address\"] <= ip) &\n",
    "        (ip_df[\"upper_bound_ip_address\"] >= ip)\n",
    "    ]\n",
    "    if not match.empty:\n",
    "        return match.iloc[0][\"country\"]\n",
    "    return \"Unknown\"\n",
    "\n",
    "fraud_df[\"country\"] = fraud_df[\"ip_int\"].apply(find_country)\n",
    "\n",
    "print(fraud_df[\"country\"].value_counts().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "251b5951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country feature successfully added\n"
     ]
    }
   ],
   "source": [
    "assert \"country\" in fraud_df.columns\n",
    "print(\"Country feature successfully added\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd923c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'signup_time', 'purchase_time', 'purchase_value',\n",
       "       'device_id', 'source', 'browser', 'sex', 'age', 'ip_address', 'class',\n",
       "       'time_since_signup', 'hour_of_day', 'day_of_week',\n",
       "       'user_transaction_count', 'time_since_last_tx', 'country_x',\n",
       "       'country_y', 'country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0f68d8",
   "metadata": {},
   "source": [
    "## Fraud_Data Feature Engineering\n",
    "\n",
    "We begin by converting timestamps and creating time-based features\n",
    "that capture user behavior and transaction timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3996834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to datetime...\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting to datetime...\")\n",
    "fraud_df[\"signup_time\"] = pd.to_datetime(fraud_df[\"signup_time\"])\n",
    "fraud_df[\"purchase_time\"] = pd.to_datetime(fraud_df[\"purchase_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5a6e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time since signup\n"
     ]
    }
   ],
   "source": [
    "print(\"Time since signup\")\n",
    "fraud_df[\"time_since_signup\"] = (\n",
    "    fraud_df[\"purchase_time\"] - fraud_df[\"signup_time\"]\n",
    ").dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88159fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hour and day features\n"
     ]
    }
   ],
   "source": [
    "print(\"Hour and day features\")\n",
    "fraud_df[\"hour_of_day\"] = fraud_df[\"purchase_time\"].dt.hour\n",
    "fraud_df[\"day_of_week\"] = fraud_df[\"purchase_time\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e311f955",
   "metadata": {},
   "source": [
    "### Transaction Velocity\n",
    "\n",
    "Fraudulent users often perform multiple transactions in a short time window.\n",
    "We compute transaction frequency per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c716c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting by user and time\n"
     ]
    }
   ],
   "source": [
    "print(\"Sorting by user and time\")\n",
    "fraud_df = fraud_df.sort_values([\"user_id\" , \"purchase_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06689b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions per user\n"
     ]
    }
   ],
   "source": [
    "print(\"Transactions per user\")\n",
    "fraud_df[\"user_transaction_count\"] = fraud_df.groupby(\"user_id\")[\"purchase_time\"].transform(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cd118e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time between tranasactions\n"
     ]
    }
   ],
   "source": [
    "print(\"Time between tranasactions\")\n",
    "fraud_df[\"time_since_last_tx\"] = fraud_df.groupby(\"user_id\")[\"purchase_time\"].diff().dt.total_seconds()\n",
    "fraud_df[\"time_since_last_tx\"] = fraud_df[\"time_since_last_tx\"].fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9e2429",
   "metadata": {},
   "source": [
    "### Leakage Prevention\n",
    "\n",
    "Raw timestamps and identifiers are removed to prevent data leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91ba0309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop unused columns\n"
     ]
    }
   ],
   "source": [
    "print(\"Drop unused columns\")\n",
    "fraud_df_model = fraud_df.drop(\n",
    "    columns=[\"signup_time\", \"purchase_time\", \"ip_address\", \"device_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9216d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'signup_time', 'purchase_time', 'purchase_value',\n",
       "       'device_id', 'source', 'browser', 'sex', 'age', 'ip_address', 'class',\n",
       "       'time_since_signup', 'hour_of_day', 'day_of_week',\n",
       "       'user_transaction_count', 'time_since_last_tx', 'country_x',\n",
       "       'country_y', 'country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a9acd",
   "metadata": {},
   "source": [
    "## PART B â€” Preprocessing Pipeline (Fraud_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0518b19",
   "metadata": {},
   "source": [
    "## Fraud_Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42b8503",
   "metadata": {},
   "source": [
    "### Class Imbalance Handling (Fraud_Data)\n",
    "\n",
    "SMOTE was not applied due to the presence of high-cardinality categorical features.\n",
    "Applying SMOTE would require generating artificial categorical values, which is\n",
    "statistically invalid.\n",
    "\n",
    "Instead, class-weighted models are used to handle imbalance while preserving\n",
    "data integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7491dca",
   "metadata": {},
   "source": [
    "## Class imbalance handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ebefe5",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "Stratified splitting preserves fraud distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "158417a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used for modeling:\n",
      "['user_id', 'purchase_value', 'source', 'browser', 'sex', 'age', 'time_since_signup', 'hour_of_day', 'day_of_week', 'user_transaction_count', 'time_since_last_tx', 'country']\n",
      "Train fraud ratio:  <bound method Series.mean of 50483     0\n",
      "95633     0\n",
      "139041    0\n",
      "28331     0\n",
      "123407    0\n",
      "         ..\n",
      "137700    0\n",
      "13103     0\n",
      "22126     0\n",
      "9121      0\n",
      "120156    0\n",
      "Name: class, Length: 120889, dtype: int64>\n",
      "Test fraud ratio: 0.09363729609899746\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "feature_cols = [\n",
    "    \"user_id\",\n",
    "    \"purchase_value\",\n",
    "    \"source\",\n",
    "    \"browser\",\n",
    "    \"sex\",\n",
    "    \"age\",\n",
    "    \"time_since_signup\",\n",
    "    \"hour_of_day\",\n",
    "    \"day_of_week\",\n",
    "    \"user_transaction_count\",\n",
    "    \"time_since_last_tx\",\n",
    "    \"country\"   # ðŸ”¥ THIS WAS MISSING\n",
    "]\n",
    "\n",
    "X = fraud_df[feature_cols]\n",
    "y = fraud_df[\"class\"]\n",
    "\n",
    "print(\"Features used for modeling:\")\n",
    "print(X.columns.tolist())\n",
    "\n",
    "Xf_train, Xf_test, yf_train, yf_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    "    \n",
    ")\n",
    "print(\"Train fraud ratio: \", yf_train.mean)\n",
    "print(\"Test fraud ratio:\", yf_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2e237f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'purchase_value', 'source', 'browser', 'sex', 'age',\n",
      "       'time_since_signup', 'hour_of_day', 'day_of_week',\n",
      "       'user_transaction_count', 'time_since_last_tx', 'country'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933aa707",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "17f34754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features scaled\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "num_cols = [\n",
    "    \"purchase_value\",\n",
    "    \"age\",\n",
    "    \"time_since_signup\",\n",
    "    \"user_transaction_count\",\n",
    "    \"time_since_last_tx\"\n",
    "]\n",
    "\n",
    "Xf_train[num_cols] = scaler.fit_transform(Xf_train[num_cols])\n",
    "Xf_test[num_cols] = scaler.transform(Xf_test[num_cols])\n",
    "\n",
    "print(\"Numerical features scaled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "552beb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'purchase_value', 'source', 'browser', 'sex', 'age',\n",
      "       'time_since_signup', 'hour_of_day', 'day_of_week',\n",
      "       'user_transaction_count', 'time_since_last_tx', 'country'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Xf_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a080ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (120889, 12)\n",
      "X_test shape: (30223, 12)\n",
      "y_train distribution:\n",
      " class\n",
      "0    109568\n",
      "1     11321\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", Xf_train.shape)\n",
    "print(\"X_test shape:\", Xf_test.shape)\n",
    "print(\"y_train distribution:\\n\", yf_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab750e",
   "metadata": {},
   "source": [
    "## Hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "155dd066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding completed\n"
     ]
    }
   ],
   "source": [
    "Xf_train = pd.get_dummies(\n",
    "    Xf_train,\n",
    "    columns=[\"source\", \"browser\", \"sex\", \"country\"],\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "Xf_test = pd.get_dummies(\n",
    "    Xf_test,\n",
    "    columns=[\"source\", \"browser\", \"sex\", \"country\"],\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "Xf_train, Xf_test = Xf_train.align(Xf_test, join=\"left\", axis=1, fill_value=0)\n",
    "\n",
    "print(\"One-hot encoding completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed8bbf",
   "metadata": {},
   "source": [
    "## PART C â€” Feature Prep for Credit Card Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b8eae6",
   "metadata": {},
   "source": [
    "## Credit Card Dataset Preparation\n",
    "\n",
    "PCA features are already standardized.\n",
    "Only `Time` and `Amount` require scaling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4498517",
   "metadata": {},
   "source": [
    "## Feature Engineering Summary\n",
    "\n",
    "Completed:\n",
    "- Time-based features\n",
    "- Transaction velocity features\n",
    "- Geographic enrichment\n",
    "- Scaling and encoding\n",
    "- Class imbalance handling\n",
    "- Leakage prevention\n",
    "\n",
    "Datasets are now fully prepared for modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1fc8ad",
   "metadata": {},
   "source": [
    "## Summary of Feature Engineering (Fraud_Data)\n",
    "\n",
    "In this notebook, we prepared the e-commerce fraud dataset for modeling by:\n",
    "- Cleaning and validating raw transaction data\n",
    "- Engineering time-based and behavioral features (transaction velocity, recency)\n",
    "- Integrating geolocation data via IP-to-country range mapping\n",
    "- Scaling numerical features using StandardScaler\n",
    "- Encoding categorical variables using one-hot encoding\n",
    "- Preserving class imbalance to be handled at the modeling stage\n",
    "\n",
    "The resulting dataset is fully numeric, free of missing values, and ready for machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bcbc2a",
   "metadata": {},
   "source": [
    "### Class Imbalance Handling Decision\n",
    "\n",
    "For the e-commerce fraud dataset, we did not apply SMOTE during feature engineering.\n",
    "This is because:\n",
    "- Tree-based ensemble models (e.g., Random Forest, XGBoost) are robust to class imbalance\n",
    "- SMOTE can distort categorical patterns and transaction sequences\n",
    "- Class imbalance will instead be handled using:\n",
    "  - Stratified sampling\n",
    "  - Class-weighted models\n",
    "  - Precisionâ€“Recall focused evaluation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64f0e1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed fraud dataset saved successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "\n",
    "Xf_train.to_csv(\"data/processed/fraud_X_train.csv\", index=False)\n",
    "Xf_test.to_csv(\"data/processed/fraud_X_test.csv\", index=False)\n",
    "yf_train.to_csv(\"data/processed/fraud_y_train.csv\", index=False)\n",
    "yf_test.to_csv(\"data/processed/fraud_y_test.csv\", index=False)\n",
    "\n",
    "print(\"Processed fraud dataset saved successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
